{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Wine Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = pd.read_csv('../data/wine_50comments.csv')\n",
    "# wine.drop(columns=['Unnamed: 0', 'created_utc'], inplace=True)\n",
    "# wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      int64\n",
       "subreddit      object\n",
       "body           object\n",
       "created_utc     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.dtypes\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# wine = pd.read_csv('../data/wine_comments.csv')\n",
    "# wine.drop(columns=['Unnamed: 0', 'created_utc'], inplace=True)\n",
    "# wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine['body'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word in body of subreddit \n",
    "words = wine['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this will count the number of tokens in the wine['body'] before any cleaning\n",
    "\n",
    "def word_count(series):\n",
    "    list_tokens = [w.lower() for w in series]\n",
    "    string_tokens = str(list_tokens)\n",
    "    tokens = BeautifulSoup(string_tokens).get_text()\n",
    "    return tokens\n",
    "\n",
    "len(word_count(wine['body']).split())\n",
    "\n",
    "# 1718955 words before cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put stopwords here: may want to append to 'english' \n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.append('like')\n",
    "stop_words.append('one')\n",
    "# stop_words.append('oz')\n",
    "# stop_words.append('wine')\n",
    "# stop_words.append('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from NLP1 lesson from Matt Bremms GA DSI 11\n",
    "\n",
    "# Instantiate the models \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def status_words(status):\n",
    "    '''takes a series and cleans the text data '''\n",
    "    \n",
    "    review_text = BeautifulSoup(status).get_text()\n",
    "    # Removed HTLM\n",
    "    \n",
    "    letters_only = re.sub('[^a-zA-Z]', ' ', review_text)\n",
    "    # Removed Non Letter\n",
    "    \n",
    "    words = letters_only.lower().split()\n",
    "    # Tokenize without official tokenizer\n",
    "    \n",
    "    #stops = set(stopwords.words('english'))\n",
    "        #need to add 'like' 'one'\n",
    "    stops = set(stop_words)\n",
    "    # Remove Stopwords\n",
    "    \n",
    "    meaningful_words = [lemmatizer.lemmatize(w) for w in words if w not in stops]\n",
    "#     meaningful_words = [stemmer.stem(w) for w in words if w not in stops]\n",
    "    # list\n",
    "\n",
    "    return(' '.join(meaningful_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test out some lines to see what the lemmatizer is doing \n",
    "\n",
    "original_text = wine['body'][9876].split()\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmy = [lemmatizer.lemmatize(w) for w in original_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare tokens to lemmatized version. \n",
    "# NLP1 Danielle Medellin (she/her) - NYC\n",
    "\n",
    "list(zip(original_text, lemmy))\n",
    "\n",
    "for a, b in zip(original_text, lemmy):\n",
    "    if a != b:\n",
    "        print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test out some lines to see what the stemmer is doing \n",
    "# original_text = wine['body'][34].split()\n",
    "\n",
    "# stem_words = [stemmer.stem(w) for w in original_text]\n",
    "\n",
    "# # Compare tokens to lemmatized version. \n",
    "# # NLP1 Danielle Medellin (she/her) - NYC\n",
    "\n",
    "# list(zip(original_text, stem_words))\n",
    "\n",
    "# for a, b in zip(original_text, stem_words):\n",
    "#     if a != b:\n",
    "#         print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add a column onto DF with clean data\n",
    "# I want to keep the orginal data as well for comparision \n",
    "\n",
    "wine['body_clean'] = wine['body'].map(status_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original \n",
    "wine['body'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same line clean \n",
    "wine['body_clean'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/find-k-frequent-words-data-set-python/\n",
    "# Top 10 most common words from cleaned data \n",
    "\n",
    "clean_tokens = word_count(wine['body_clean'])\n",
    "count = Counter(clean_tokens.split())\n",
    "top_wine = count.most_common(10)\n",
    "top_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visually look at this \n",
    "\n",
    "names, values = zip(*top_wine)\n",
    "\n",
    "x=values\n",
    "y=names\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.barh(y, x);\n",
    "plt.title('Top 10 Wine Words', fontsize=18);\n",
    "plt.xticks(fontsize=14);\n",
    "plt.yticks(fontsize=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 most common words from original data \n",
    "\n",
    "clean_tokens = word_count(wine['body'])\n",
    "count = Counter(clean_tokens.split())\n",
    "count.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for 20K pull \n",
    "# wine.to_csv('../data/clean_wine.csv', index=None)\n",
    "\n",
    "# save changes to_csv for next notebook \n",
    "# comment out to prevent accidental override"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this if for 50K pull\n",
    "\n",
    "# wine.to_csv('../data/clean_50wine.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the cleaning step by step to see how it is working beginning to end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.loc[400:410]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = BeautifulSoup(wine['body'][498])\n",
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1 = ex.get_text()\n",
    "ex1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex2 = re.sub('[^a-zA-Z]', ' ', ex1)\n",
    "ex2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex3 = ex2.lower().split()\n",
    "ex3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = set(stop_words)\n",
    "ex4 = [lemmatizer.lemmatize(w) for w in ex3 if w not in stops]\n",
    "ex4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
